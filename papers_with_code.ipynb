{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, json\n",
    "import tkinter as tk\n",
    "import tkinter.ttk as ttk\n",
    "from tkinter import scrolledtext\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageTk\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "from parse_pdf import *\n",
    "from txt_processing import *\n",
    "\n",
    "\n",
    "df, df_dwn, tokens, bag_of_words, bag_words_idf, doc_all, doc_all_tfidf = data(update=False)\n",
    "\n",
    "wc = wrdcld(tokens)\n",
    "wc.to_file(\"./pic/1.png\")\n",
    "\n",
    "# tkinter ----------------------------------------------------------\n",
    "window = tk.Tk()\n",
    "window.title(\"Papers with Code: the latest in Machine Learning\")\n",
    "window.geometry('900x700')\n",
    "\n",
    "# Disable resizing the GUI\n",
    "window.resizable(0,0)\n",
    "\n",
    "tab_control = ttk.Notebook(window) \n",
    "\n",
    "# Frame -----------------------------------------\n",
    "tab1 = ttk.Frame(tab_control)\n",
    "tab2 = ttk.Frame(tab_control)\n",
    "tab3 = ttk.Frame(tab_control)\n",
    "tab_control.add(tab1, text='WordCloud: gives frequencies of tokens') \n",
    "tab_control.add(tab2, text='Query: gives similarities')\n",
    "tab_control.add(tab3, text='Papers & Codes: gives urls') \n",
    "\n",
    "# WordCloud -------------------------------------\n",
    "path_1 = \"./pic/1.png\"\n",
    "img_1 = Image.open(path_1)\n",
    "photo_1 = ImageTk.PhotoImage(img_1)\n",
    "lbl1 = tk.Label(tab1, image = photo_1)\n",
    "lbl1.pack()\n",
    "\n",
    "# Query ------------------------------------------\n",
    "## input que\n",
    "que = tk.Entry(tab2, width=100)\n",
    "que.pack()\n",
    "\n",
    "\n",
    "def clicked():\n",
    "    txt = que.get()\n",
    "    q = query(txt, bag_words_idf, doc_all_tfidf)\n",
    "    plot_query(q)\n",
    "    \n",
    "    path = \"./pic/query.png\"\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((840, 260),Image.ANTIALIAS)\n",
    "    photo = ImageTk.PhotoImage(img)\n",
    "    lbl2.configure(image=photo)\n",
    "    lbl2.image = photo\n",
    "\n",
    "    for paper in q.keys():\n",
    "        gitList.insert(tk.END, f'{paper}\\n')\n",
    "        for j in (df_dwn[df_dwn['pdf_title'] == str(paper)+'.pdf']['paper_pdf']):\n",
    "            gitList.insert(tk.END, f\"Paper: {j}\\n\")\n",
    "        for i in df.iloc[list(chain.from_iterable(df_dwn[df_dwn['pdf_title'] == str(paper)+'.pdf']['github_index']))]['repo_url']:\n",
    "            gitList.insert(tk.END, f'{i}\\n')\n",
    "        gitList.insert(tk.END, '\\n---------------------------------------------------------------------------------------------\\n')\n",
    "    \n",
    "\n",
    "btn = tk.Button(tab2, text='Search', command=clicked)\n",
    "btn.pack()\n",
    "    \n",
    "path_2 = \"./pic/query.png\"\n",
    "img_2 = Image.open(path_2)\n",
    "img_2 = img_2.resize((840, 260),Image.ANTIALIAS)\n",
    "photo_2 = ImageTk.PhotoImage(img_2)\n",
    "lbl2 = tk.Label(tab2, image = photo_2)\n",
    "lbl2.pack(fill='both')\n",
    "\n",
    "# github address\n",
    "scroll = tk.Scrollbar(tab3)\n",
    "scroll.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "gitList = tk.Listbox(tab3, width=900, height=700, yscrollcommand=scroll.set)\n",
    "gitList.pack(side=tk.LEFT)\n",
    "scroll.config(command=gitList.yview)\n",
    "\n",
    "tab_control.pack(expand=1, fill='both')\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = {'Independently Recurrent Neural Network -IndRNN-- Building A Longer and Deeper RNN': 0.05657069692198369,\n",
    " 'Resting state fMRI functional connectivity-based classification using a convolutional neural network architecture': 0.052594601909672356,\n",
    " 'Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models': 0.04483515451978526,\n",
    " 'Cryptocurrency Portfolio Management with Deep Reinforcement Learning': 0.03556211732032799,\n",
    " 'DeepCD- Learning Deep Complementary Descriptors for Patch Representations': 0.03130964801877467,\n",
    " 'PointNet- Deep Learning on Point Sets for 3D Classification and Segmentation': 0.027982244142928603,\n",
    " 'DeepLab- Semantic Image Segmentation with Deep Convolutional Nets- Atrous Convolution- and Fully Connected CRFs': 0.024146446032890956,\n",
    " 'Dynamic Routing Between Capsules': 0.018713917498992205,\n",
    " 'Decoupled Weight Decay Regularization': 0.01266831873771479,\n",
    " 'Mask R-CNN': 0.009420915541980435}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "git = ''\n",
    "for paper in q.keys():\n",
    "    git += f'{paper}\\n\\n'\n",
    "    for j in (df_dwn[df_dwn['pdf_title'] == str(paper)+'.pdf']['paper_pdf']):\n",
    "        git += f\"Paper: {j}\\n\\n\"\n",
    "    for i in df.iloc[list(chain.from_iterable(df_dwn[df_dwn['pdf_title'] == str(paper)+'.pdf']['github_index']))]['repo_url']:\n",
    "        git += f'{i}\\n'\n",
    "    git += '\\n---------------------------------------------------------------------------------------------\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
